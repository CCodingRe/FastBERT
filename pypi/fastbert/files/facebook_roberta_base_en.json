{
    "emb_size": 768,
    "feedforward_size": 3072,
    "hidden_size": 768,
    "heads_num": 12,
    "layers_num": 12,
    "dropout": 0.1,
    "embedding": "bert",
    "encoder": "bert",
    "pooling": "first",
    "vocab_path": "google_zh_vocab.txt",
    "pretrained_model_path": "facebook_roberta_base_en.bin",
    "pretrained_model_md5": "",
    "pretrained_model_url": "",
    "pretrained_model_url_bak": ""
}
